import re
import json

def get_emoji_pattern():
    return re.compile(
        "[" +
        "\U0001F600-\U0001F64F"
        "\U0001F300-\U0001F5FF"
        "\U0001F680-\U0001F6FF"
        "\U0001F1E0-\U0001F1FF"
        "\U00002700-\U000027BF"
        "\U0001F900-\U0001F9FF"
        "\U00002600-\U000026FF"
        "]", flags=re.UNICODE
    )

def get_allowed_char_pattern():
    allowed = (
        r'ê°€-í£'
        r'a-zA-Z0-9'
        r' .,!?~'
        r'ğŸ¾ğŸ˜¢ğŸ”¥ğŸ˜¤â“â¤ï¸ğŸ§¡ğŸ’›ğŸ’šğŸ’™ğŸ’œğŸ–¤ğŸ¤ğŸ¤'
        r'ğŸ•ğŸ©ğŸˆğŸˆâ€â¬›ğŸ±ğŸ¶ğŸ˜¹ğŸ˜ºğŸ˜¸ğŸ˜»ğŸ˜¼ğŸ˜½ğŸ˜¾ğŸ˜¿ğŸ«¨'
        r'ğŸ˜€ğŸ˜ğŸ˜‚ğŸ¤£ğŸ˜ƒğŸ˜„ğŸ˜…ğŸ˜†ğŸ˜‰ğŸ˜ŠğŸ˜‹ğŸ˜ğŸ˜ğŸ˜˜ğŸ¥°ğŸ˜—ğŸ˜™ğŸ˜šğŸ™‚ğŸ¤—ğŸ¤©'
        r'ğŸ¤”ğŸ¤¨ğŸ˜ğŸ˜‘ğŸ˜¶ğŸ™„ğŸ˜ğŸ˜£ğŸ˜¥ğŸ˜®ğŸ¤ğŸ˜¯ğŸ˜ªğŸ˜«ğŸ¥±ğŸ˜´ğŸ˜ŒğŸ˜›ğŸ˜œğŸ˜ğŸ¤¤'
        r'ğŸ˜’ğŸ˜“ğŸ˜”ğŸ˜•ğŸ™ƒğŸ¤‘ğŸ˜²â˜¹ï¸ğŸ™ğŸ˜–ğŸ˜ğŸ˜ŸğŸ˜¤ğŸ˜¢ğŸ˜­ğŸ˜¦ğŸ˜§ğŸ˜¨ğŸ˜©ğŸ¤¯ğŸ˜¬ğŸ˜°ğŸ˜±ğŸ˜³ğŸ¥ºğŸ˜µğŸ¥¶ğŸ¥µğŸ˜¡ğŸ˜ ğŸ¤¬ğŸ˜·ğŸ¤’ğŸ¤•ğŸ¤¢ğŸ¤®ğŸ¥µğŸ¥¶ğŸ¥´ğŸ¤§'
        r'ğŸ»ğŸ¦ŠğŸ¼ğŸ·ğŸ®ğŸ¸ğŸµğŸ”ğŸ¦„ğŸ¦ğŸ¯ğŸ´ğŸ¦“ğŸ¦ğŸ§ğŸ¦†ğŸ¦‰ğŸ¦‡ğŸ¦œğŸ¦‹'
        r'ğŸ–ğŸ—ğŸ•ğŸ”ğŸŸğŸŒ­ğŸ¿ğŸ©ğŸªğŸ«ğŸ¬ğŸ­ğŸ¡ğŸ¨ğŸ§ğŸ¦ğŸ¤ğŸ£ğŸšğŸ™ğŸ˜ğŸ¥šğŸ¥ğŸ¥¯ğŸ¥ğŸ¥–ğŸğŸ¥¨'
        r'â¤ï¸ğŸ§¡ğŸ’›ğŸ’šğŸ’™ğŸ’œğŸ–¤ğŸ¤ğŸ¤ğŸ’”ğŸ’•ğŸ’ğŸ’“ğŸ’—ğŸ’–ğŸ’˜ğŸ’ğŸ’Ÿ'
        r'ğŸ’¤ğŸ’¢ğŸ’¦ğŸ’§ğŸ’«ğŸ’¥ğŸ’¬ğŸ’­ğŸ—¯ï¸âœ¨â­ğŸŒŸğŸ”¥ğŸŒˆâ˜ï¸â›ˆï¸â„ï¸ğŸŒ¤ï¸ğŸŒ™â˜€ï¸'
    )
    return re.compile(rf'[^{allowed}]')

def clean_text(text):
    # 1. rn, \r\n, \n, \r â†’ ê³µë°±
    text = re.sub(r"(\\r\\n|\\n|\\r|rn)", " ", text)
    # 2. URL ì œê±°
    text = re.sub(r"https?://\S+|www\.\S+", "", text)
    # 3. í—ˆìš© ë¬¸ì ì´ì™¸ ì‚­ì œ
    text = get_allowed_char_pattern().sub("", text)
    # 4. ë™ì¼ ë¬¸ì 4íšŒ ì´ìƒ ë°˜ë³µ â†’ 2íšŒ, ë™ì¼ ì´ëª¨ì§€ 4íšŒ ì´ìƒ ë°˜ë³µ â†’ 3íšŒ
    text = re.sub(r'(\S{1,5})\1{3,}', r'\1\1', text)
    text = re.sub(r'((?:' + get_emoji_pattern().pattern + r')){4,}', lambda m: m.group(0)[:3], text)
    # 5. ë‹¤ì¤‘ ê³µë°± ì •ë¦¬
    text = re.sub(r'\s+', ' ', text).strip()
    return text

def clean_jsonl_replace_fields(
    input_path,
    output_path,
    fields=("content", "transformed_content")
):
    written = 0
    with open(input_path, "r", encoding="utf-8") as fin, open(output_path, "w", encoding="utf-8") as fout:
        for idx, line in enumerate(fin):
            data = json.loads(line)
            for field in fields:
                if field in data and isinstance(data[field], str):
                    data[field] = clean_text(data[field])
            # ë‘˜ ì¤‘ í•˜ë‚˜ë¼ë„ ë¹ˆ ë¬¸ìì—´ì´ë©´ ì €ì¥í•˜ì§€ ì•ŠìŒ
            if any(data.get(field, "").strip() == "" for field in fields):
                continue
            fout.write(json.dumps(data, ensure_ascii=False) + "\n")
            written += 1
    print(f"[í´ëœì§•] content, transformed_content ë‘˜ ë‹¤ ë¹ˆ ê°’ì´ ì•„ë‹Œ {written}ê°œë§Œ ì €ì¥ ì™„ë£Œ")

if __name__ == "__main__":
    input_path = "/Users/jaeseoksee/Documents/project/for_AI/my_project/Finetuning/dataset/_dataset/_made/dataset_0709_made.jsonl"
    output_path = "/Users/jaeseoksee/Documents/project/for_AI/my_project/Finetuning/dataset/_dataset/_filtered/dataset_0709_made_clean.jsonl"
    clean_jsonl_replace_fields(input_path, output_path)
