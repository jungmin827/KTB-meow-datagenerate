import streamlit as st
import os, json
import tempfile
import subprocess
import pandas as pd
from io import BytesIO
from functions.visualize import load_eval_results, get_mean_scores, plot_radar_chart_multi, plot_score_distribution, show_mean_score_table
from functions.feature_count import get_data_distribution
from functions.filtering import filter_jsonl_bytes_by_threshold

# =========================
# ìºì‹œ í´ë” ê´€ë ¨ í•¨ìˆ˜
# =========================
CACHE_DIR = "./cache"

def ensure_cache_dir():
    if not os.path.exists(CACHE_DIR):
        os.makedirs(CACHE_DIR)

def save_eval_to_cache(filename: str, eval_bytes: bytes, mean_scores: dict, dist: dict, data_bytes: bytes):
    ensure_cache_dir()
    base = os.path.splitext(filename)[0]
    with open(os.path.join(CACHE_DIR, f"{base}_eval.jsonl"), "wb") as f:
        f.write(eval_bytes)
    with open(os.path.join(CACHE_DIR, f"{base}_mean.json"), "w", encoding="utf-8") as f:
        json.dump(mean_scores, f, ensure_ascii=False)
    with open(os.path.join(CACHE_DIR, f"{base}_dist.json"), "w", encoding="utf-8") as f:
        json.dump(dist, f, ensure_ascii=False)
    with open(os.path.join(CACHE_DIR, f"{base}_data.jsonl"), "wb") as f:
        f.write(data_bytes)

def load_all_cached_files():
    ensure_cache_dir()
    cached = {}
    for fname in os.listdir(CACHE_DIR):
        if fname.endswith("_eval.jsonl"):
            base = fname.replace("_eval.jsonl", "")
            try:
                with open(os.path.join(CACHE_DIR, f"{base}_eval.jsonl"), "rb") as f:
                    eval_bytes = f.read()
                with open(os.path.join(CACHE_DIR, f"{base}_mean.json"), "r", encoding="utf-8") as f:
                    mean_scores = json.load(f)
                with open(os.path.join(CACHE_DIR, f"{base}_dist.json"), "r", encoding="utf-8") as f:
                    dist = json.load(f)
                with open(os.path.join(CACHE_DIR, f"{base}_data.jsonl"), "rb") as f:
                    data_bytes = f.read()
                cached[f"{base}.jsonl"] = {
                    "data": data_bytes,
                    "eval": eval_bytes,
                    "mean_scores": mean_scores,
                    "dist": dist
                }
            except Exception as e:
                continue
    return cached

# Streamlit ì—…ë¡œë“œ-ìºì‹œ-ì„¸ì…˜ ê´€ë¦¬ 
def remove_file_from_cache(filename):
    base = os.path.splitext(filename)[0]
    if filename in st.session_state["cached_files"]:
        del st.session_state["cached_files"][filename]
    for suffix in ["_eval.jsonl", "_mean.json", "_dist.json", "_data.jsonl"]:
        try:
            os.remove(os.path.join(CACHE_DIR, f"{base}{suffix}"))
        except Exception:
            pass

# =========================
# Streamlit ì•± ì‹œì‘
# =========================
st.title("ë§íˆ¬ë³€í™˜ ëª¨ë¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")

# --- ìºì‹œ í´ë”ì—ì„œ ê¸°ì¡´ í‰ê°€ ê²°ê³¼ ìë™ ë¡œë”© ---
if "cached_files" not in st.session_state:
    st.session_state["cached_files"] = load_all_cached_files()

# ê·œì¹™ ë³´ê¸° toggle
if st.toggle("ë°ì´í„° ì—…ë¡œë“œ ê·œì¹™ ë³´ê¸°(ì—…ë¡œë“œ ì¤‘ ê¸ˆì§€)"):
    st.markdown("""
    ### ë°ì´í„° ì—…ë¡œë“œ ê·œì¹™

    #### 1. **íŒŒì¼ í¬ë§·**
    - **í˜•ì‹:** `.jsonl` (JSON Lines, í•œ ì¤„ì— í•˜ë‚˜ì˜ JSON ê°ì²´)
    - **ì¸ì½”ë”©:** `UTF-8`

    #### 2. **í•„ìˆ˜ í•„ë“œ ë° ì˜ˆì‹œ**
    | í•„ë“œëª…                | ì„¤ëª…                        | ì˜ˆì‹œ ê°’                      |
    |-----------------------|-----------------------------|------------------------------|
    | `post_type`           | ë™ë¬¼ ìœ í˜•                   | `"cat"`, `"dog"`             |
    | `emotion`             | ê°ì •                        | `"normal"`, `"happy"`, `"sad"`, `"angry"`, `"grumpy"`, `"curious"` |
    | `content`             | ì…ë ¥ ë¬¸ì¥                   | `"ì˜¤ëŠ˜ì€ ë­˜ í•˜ê³  ë†€ê¹Œ?"`      |
    | `transformed_content` | ë³€í™˜(ì¶œë ¥) ë¬¸ì¥             | `"ë©. ì˜¤ëŠ˜ ë­í•˜ê³  ë†€ì§€? ..."`  |

    #### 3. **JSONL ì˜ˆì‹œ**
    ```json
    {
    "post_type": "dog",
    "emotion": "normal",
    "content": "ì˜¤ëŠ˜ì€ ë­˜ í•˜ê³  ë†€ê¹Œ?",
    "transformed_content": "ë©. ì˜¤ëŠ˜ ë­í•˜ê³  ë†€ì§€? ë¹¨ë¦¬ ë†€ê³  ì‹¶ë‹¤ë©. ğŸ¾"
    }
    ```

    #### 4. **í‰ê°€ ëŒ€ìƒ ë™ë¬¼/ê°ì •**
    - **ë™ë¬¼(post_type):**  
    - `cat` (ê³ ì–‘ì´)  
    - `dog` (ê°•ì•„ì§€)
    - **ê°ì •(emotion):**  
    - `normal` (ì¼ë°˜)  
    - `happy` (ê¸°ì¨)  
    - `sad` (ìŠ¬í””)  
    - `angry` (ë¶„ë…¸)  
    - `grumpy` (ê¹Œì¹ )  
    - `curious` (í˜¸ê¸°ì‹¬)

    #### 5. **ì—…ë¡œë“œ ì‹œ ì£¼ì˜ì‚¬í•­**
    - ê° ì¤„ë§ˆë‹¤ í•˜ë‚˜ì˜ JSON ê°ì²´ë§Œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
    - ëª¨ë“  í•„ë“œëŠ” ë°˜ë“œì‹œ í¬í•¨ë˜ì–´ì•¼ í•˜ë©°, ê°’ì´ ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ë¡œ ì…ë ¥í•˜ì„¸ìš”.
    - íŒŒì¼ í¬ê¸°ëŠ” 10MB ì´í•˜ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.
    - í‰ê°€ ì ìˆ˜(`kobert_score`, `type_score`, `quality_score`, `bleu_score`, `perplexity_score` ë“±)ëŠ” í‰ê°€ê°€ ëë‚œ íŒŒì¼ì—ë§Œ í¬í•¨ë©ë‹ˆë‹¤.

    #### 6. **í‰ê°€ ê¸°ì¤€ ë° ì˜ë¯¸**
    | ì ìˆ˜ëª…              | ì˜ë¯¸                                                             | íŠ¹ì§•     |
    |-------------------|-----------------------------------------------------------------|---------|
    | kobert_score      | KoBERT ê¸°ë°˜ ì˜ë¯¸ ìœ ì‚¬ë„ (ì›ë¬¸ê³¼ ë³€í™˜ë¬¸ì¥ì˜ ì˜ë¯¸ê°€ ì–¼ë§ˆë‚˜ ìœ ì‚¬í•œì§€ í‰ê°€)        | 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì˜ë¯¸ê°€ ìœ ì‚¬í•¨ (ìµœëŒ€ 1) |
    | type_score        | ë§íˆ¬/ìŠ¤íƒ€ì¼ ì í•©ì„± (ë™ë¬¼/ê°ì •ë³„ ìš”êµ¬ ì¡°ê±´ì— ë§ëŠ”ì§€ í‰ê°€)                     | 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë§íˆ¬/ìŠ¤íƒ€ì¼ì´ ì í•© (ìµœëŒ€ 1) |
    | quality_score     | í’ˆì§ˆ(ì˜ë¯¸ ë³´ì¡´, ìŠ¤íƒ€ì¼ ì¼ì¹˜, ìì—°ìŠ¤ëŸ¬ì›€, í˜•ì‹ ì í•©ì„± ë“± ë³€í™˜ë¬¸ì¥ í’ˆì§ˆ í‰ê°€)      | 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ í’ˆì§ˆì´ ìš°ìˆ˜ (ìµœëŒ€ 1) |
    | bleu_score        | BLEU ì ìˆ˜ (ì›ë¬¸ê³¼ ë³€í™˜ë¬¸ì¥ ê°„ n-gram ê¸°ë°˜ ìœ ì‚¬ë„, ê¸°ê³„ë²ˆì—­ í’ˆì§ˆ ì§€í‘œ)        | `bleu_score / 0.1` ë¡œ 10ë°° ê°’ ì‚¬ìš©(ìµœëŒ€ 1) |
    | perplexity_score  | ë¬¸ì¥ ìì—°ìŠ¤ëŸ¬ì›€ (ì–¸ì–´ëª¨ë¸ ê¸°ë°˜ Perplexity, ë‚®ì„ìˆ˜ë¡ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥)          | `0.1 / perplexity_score` ë¡œ ì—­ìˆ˜ ë° 1/10ê°’ ì‚¬ìš©(ìµœëŒ€ 1) |

    - **ëª¨ë“  ì ìˆ˜ëŠ” 0~1ë¡œ ë³€í™˜ë˜ì–´ ì‹œê°í™” ë° í•„í„°ë§ì— ì‚¬ìš©ë©ë‹ˆë‹¤.**

    #### ë°ì´í„°ì…‹ 
    | ë°ì´í„°ì…‹ íŒŒì¼ëª…                | ì£¼ìš” íŠ¹ì§• ë° ì„¤ëª…  | ë°ì´í„° ê°œìˆ˜ | 
    |-------------------------------|----------------------------------------|--------------|
    | test_made.jsonl                | í…ŒìŠ¤íŠ¸ìš© Google AI Studio í•©ì„± ë°ì´í„°.              | 100ê°œ |
    | dataset_0515_made.jsonl        | ì´ˆê¸° ìœ ì € ë°ì´í„°.                              | 342ê°œ |
    | dataset_0527_made.jsonl        | ìœ ì € ê²Œì‹œê¸€ ë°ì´í„° ê¸°ë°˜ ê°ì •ë³„/ë™ë¬¼ë³„ ë°ì´í„°            | 818ê°œ |
    | dataset_0530_made.jsonl        | ìœ ì € ê²Œì‹œê¸€ ë°ì´í„° ê¸°ë°˜ ê°ì •ë³„/ë™ë¬¼ë³„ ë°ì´í„° ê°ì •ë³„ ì¦í­   | 2,986ê°œ |
    | dataset_0613_made.jsonl        | ìœ ì € ëŒ“ê¸€ ì…ë ¥ì— ëŒ€í•œ ê·œì¹™ê¸°ë°˜ ë³€í™˜(cat) ë°ì´í„°         | 681ê°œ | 
    | dataset_0620_made.jsonl        | ìœ ì € ëŒ“ê¸€ ì…ë ¥ì— ëŒ€í•œ ê·œì¹™ê¸°ë°˜ ë³€í™˜(dog) ë°ì´í„°          | 681ê°œ | 
    | dataset_0622_made.jsonl        | í•©ì„± ì¸í’‹ì— ëŒ€í•œ Gemini ë§íˆ¬ ë³€í™˜ ìµœì¢…ë³¸            | 17,596ê°œ | 
    | dataset_0629_all.jsonl        | ì´ì „ê¹Œì§€ì˜ ëª¨ë“  ë°ì´í„°ë¥¼ í•©ì¹œ í†µí•© ë°ì´í„°.             | 21,104ê°œ | 
    | dataset_0709_made.jsonl        | ë§ì´ ì‚¬ìš©ë˜ëŠ” ë¹„ë¬¸ ë°ì´í„° ë° safty ë°ì´í„° ì¶”ê°€ | - ê°œ | 
    | dataset_0710_made.jsonl        | normal ë°ì´í„°ì— ëŒ€í•´ ëŒ“ê¸€ ë°ì´í„°ë¡œë§Œ ì‚¬ìš©     | - ê°œ | 
    | dataset_0710_all.jsonl        | 0709 + 0710 ë°ì´í„°ì…‹                     | - ê°œ | 
    ---
    **ì˜ˆì‹œ íŒŒì¼ì„ ì°¸ê³ í•˜ì—¬ ë™ì¼í•œ êµ¬ì¡°ë¡œ ë°ì´í„°ë¥¼ ì¤€ë¹„í•´ ì£¼ì„¸ìš”.**
    ë¬¸ì œê°€ ìˆìœ¼ë©´ ë‹´ë‹¹ìì—ê²Œ ë¬¸ì˜ ë°”ëë‹ˆë‹¤.
        """)

metric_labels = {
    "kobertscore_f1": "KoBERT",
    "type_score": "Type",
    "quality_score": "Quality",
    "bleu_score": "BLEU",
    "perplexity_score": "Perplexity"
}

all_metrics = list(metric_labels.keys())

# --- ì—…ë¡œë“œ íŒŒì¼ ë° í‰ê°€ ê²°ê³¼ ìºì‹± ---
uploaded_files = st.file_uploader(
    "ì—¬ëŸ¬ ê°œì˜ JSONL ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”. (ë¶„í¬ í†µê³„ ë° ëª¨ë¸ í‰ê°€ ìë™ ì§„í–‰)",
    type=["jsonl"],
    accept_multiple_files=True,
    key="data_and_eval"
)

# ìƒˆë¡œ ì—…ë¡œë“œëœ íŒŒì¼ì„ ìºì‹œì— ì €ì¥ ë° í‰ê°€/í†µê³„ ìˆ˜í–‰
if uploaded_files:
    for f in uploaded_files:
        fname = f.name
        if not fname or not isinstance(fname, str):
            st.error("ì˜ëª»ëœ íŒŒì¼ëª…ì…ë‹ˆë‹¤. íŒŒì¼ì„ ë‹¤ì‹œ ì—…ë¡œë“œ í•´ì£¼ì„¸ìš”.")
            continue
        if fname not in st.session_state["cached_files"]:
            remove_file_from_cache(fname)
            st.session_state["cached_files"][fname] = {"data": f.getvalue(), "eval": None, "mean_scores": None, "dist": None}
            dist = get_data_distribution(f.getvalue())
            st.session_state["cached_files"][fname]["dist"] = dist
            with tempfile.NamedTemporaryFile(delete=False, suffix=".jsonl") as tmp_file:
                tmp_file.write(f.getvalue())
                tmp_path = tmp_file.name
            eval_path = tmp_path.replace(".jsonl", "_eval.jsonl")
            main_eval_path = os.path.join(os.path.dirname(__file__), "functions", "main_eval.py")
            with st.spinner(f"ëª¨ë¸ í‰ê°€ ìˆ˜í–‰ ì¤‘: {fname}"):
                result = subprocess.run(
                    [
                        "python", main_eval_path,
                        "--input_path", tmp_path,
                        "--output_path", eval_path,
                        "--use_kobert", "--use_type", "--use_quality", "--use_bleu", "--use_perplexity"
                    ],
                    capture_output=True, text=True
                )
            if result.returncode != 0:
                st.error(f"í‰ê°€ ì‹¤íŒ¨: {fname}\n{result.stderr}")
                continue
            with open(eval_path, "rb") as f_eval:
                eval_jsonl_bytes = f_eval.read()
                st.session_state["cached_files"][fname]["eval"] = eval_jsonl_bytes
            results = load_eval_results(eval_path)
            mean_scores = get_mean_scores(results, all_metrics)
            st.session_state["cached_files"][fname]["mean_scores"] = mean_scores
            st.success(f"âœ… {fname} í‰ê°€ ë° í†µê³„ ì™„ë£Œ!")
            save_eval_to_cache(
                fname,
                eval_jsonl_bytes,
                mean_scores,
                dist,
                f.getvalue()
            )

# ìºì‹œ íŒŒì¼ëª… ë¦¬ìŠ¤íŠ¸ ìƒì„± ì‹œ ë¬¸ìì—´ë§Œ í¬í•¨
cached_file_names = [k for k in st.session_state["cached_files"].keys() if isinstance(k, str) and k]

selected_cached_files = st.multiselect(
    "ìºì‹œì— ì €ì¥ëœ íŒŒì¼ì„ ì„ íƒí•´ì„œ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
    cached_file_names,
    default=[],
)

st.markdown("#### í‰ê°€ ê²°ê³¼ íŒŒì¼(jsonl) ë‹¤ìš´ë¡œë“œ")
download_file = st.selectbox(
    "ë‹¤ìš´ë¡œë“œí•  í‰ê°€ ê²°ê³¼ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”.",
    cached_file_names
)
if download_file:
    eval_bytes = st.session_state["cached_files"][download_file].get("eval")
    if eval_bytes is not None:
        st.download_button(
            label=f"ë‹¤ìš´ë¡œë“œ",
            data=eval_bytes,
            file_name=f"{os.path.splitext(download_file)[0]}_eval.jsonl",
            mime="application/json"
        )
    else:
        st.warning("ë‹¤ìš´ë¡œë“œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

file_objs = []
for fname in selected_cached_files:
    if not isinstance(fname, str):
        st.error(f"ì˜ëª»ëœ fname: {fname} (type: {type(fname)})")
        continue
    file_obj = BytesIO(st.session_state["cached_files"][fname]["data"])
    file_obj.name = fname
    file_objs.append(file_obj)

scores_list = []
model_names = []
table_rows = []

if file_objs:
    st.markdown("-----------------------")
    for uploaded_file in file_objs:
        fname = uploaded_file.name
        dist = st.session_state["cached_files"][fname]["dist"]
        st.markdown(f"#### â¬‡ï¸ {fname} ë°ì´í„° ë¶„í¬ (ë™ë¬¼ë³„/ê°ì •ë³„)")
        pivot_data = []
        for post_type, emotion_counter in dist["type_emotion_counter"].items():
            row = {"post_type": post_type}
            for emotion in dist["emotion_order"]:
                row[emotion] = emotion_counter.get(emotion, 0)
            for emotion, count in emotion_counter.items():
                if emotion not in dist["emotion_order"]:
                    row[emotion] = count
            pivot_data.append(row)
        pivot_df = pd.DataFrame(pivot_data).set_index("post_type")
        st.dataframe(pivot_df, use_container_width=True)
        st.success(f"âœ… ì´ ë°ì´í„° ê°œìˆ˜: {dist['total_count']} / ì¤‘ë³µ ì—†ëŠ” ì›ë¬¸ ê°œìˆ˜: {dist['unique_content_count']}")

        model_name = os.path.splitext(fname)[0]
        model_names.append(model_name)
        mean_scores = st.session_state["cached_files"][fname]["mean_scores"]
        if mean_scores is None:
            mean_scores = {}
        table_row = {"ëª¨ë¸ëª…": model_name}
        table_row.update({metric_labels[metric]: mean_scores.get(metric, None) for metric in all_metrics})
        table_rows.append(table_row)
        scores_list.append(mean_scores)

    if table_rows:
        st.markdown("-----------------------")
        st.markdown("#### ì‹œê°í™”í•  í‰ê°€ ì§€í‘œ ë° threshold ê°’ì„ ì„ íƒí•˜ì„¸ìš”.")

        selected_metrics = []
        thresholds = {}
        cols = st.columns(len(all_metrics))

        default_thresholds = {
            "kobertscore_f1": 0.6,
            "type_score": 0.8,
            "quality_score": 0.8,
            "bleu_score": 0.2,
            "perplexity_score": 0.5,
        }
        for i, metric in enumerate(all_metrics):
            label = metric_labels[metric]
            with cols[i]:
                checked = st.session_state.get(f"metric_{metric}", True)
                if st.checkbox(label, value=checked, key=f"metric_{metric}"):
                    selected_metrics.append(metric)
                    thresholds[metric] = st.number_input(
                        f"{label} threshold", min_value=0.0, max_value=1.0,
                        value=default_thresholds.get(metric, 0.5), step=0.01, key=f"thres_{metric}"
                    )

        if scores_list and selected_metrics:
            st.markdown("#### ì„ íƒí•œ ì§€í‘œë¡œ ë ˆì´ë” ì°¨íŠ¸ ì‹œê°í™”")
            plot_radar_chart_multi(
                scores_list, model_names, selected_metrics,
                title="Evaluation Score", metric_labels=metric_labels, thresholds=thresholds
            )
            show_mean_score_table(scores_list, model_names, selected_metrics, metric_labels)


            st.markdown("#### ì„ íƒí•œ ì§€í‘œë³„ ì ìˆ˜ ë¶„í¬ (íˆìŠ¤í† ê·¸ë¨ & ë°•ìŠ¤í”Œë¡¯)")
            eval_jsonl_bytes_list = [
                st.session_state["cached_files"][fname]["eval"] for fname in selected_cached_files
            ]
            plot_score_distribution(
                eval_jsonl_bytes_list,
                [os.path.splitext(fname)[0] for fname in selected_cached_files],
                selected_metrics,
                metric_labels=metric_labels,
                thresholds=thresholds
            )

            st.markdown("-----------------------")
            st.markdown("#### ì„ íƒëœ ë°ì´í„° ì „ì²´ë¥¼ í•©ì³ì„œ í•„í„°ë§ ë° ë‹¤ìš´ë¡œë“œ")
            if selected_cached_files:
                st.markdown("**ì„ íƒëœ ë°ì´í„°ì…‹:** " + ", ".join(selected_cached_files))
            else:
                st.markdown("**ì„ íƒëœ ë°ì´í„°ì…‹ì´ ì—†ìŠµë‹ˆë‹¤.**")

            thres_str = ", ".join([f"{metric_labels[m]}: {thresholds[m]}" for m in thresholds])
            st.success(f"âœ… ì ìš©ëœ threshold ê°’: {thres_str}")

            eval_jsonl_bytes_list = [
                st.session_state["cached_files"][fname]["eval"] for fname in selected_cached_files
            ]

            if st.button("í•„í„°ë§"):
                total_before = sum(
                    len(st.session_state["cached_files"][fname]["eval"].decode("utf-8").splitlines())
                    for fname in selected_cached_files
                )
                # threshold ê¸°ì¤€ í•„í„°ë§
                filtered_data = filter_jsonl_bytes_by_threshold(eval_jsonl_bytes_list, thresholds)

                total_after = len(filtered_data)

                score_keys = set(metric_labels.keys())
                filtered_data_no_scores = []
                for d in filtered_data:
                    filtered = {k: v for k, v in d.items() if k not in score_keys}
                    filtered_data_no_scores.append(filtered)

                filtered_jsonl = "\n".join([json.dumps(d, ensure_ascii=False) for d in filtered_data_no_scores])

                st.write(f"í•„í„°ë§ ì „ ë°ì´í„° ê°œìˆ˜: {total_before} â†’ í•„í„°ë§ í›„ ë°ì´í„° ê°œìˆ˜: {total_after} (ê°ì†Œ: {total_before - total_after})")

                st.markdown("#### í•„í„°ë§ëœ ë°ì´í„°ì…‹ ë¶„í¬ í†µê³„ (í…Œì´ë¸”)")
                from functions.feature_count import get_data_distribution
                filtered_jsonl_bytes = filtered_jsonl.encode("utf-8")
                dist = get_data_distribution(filtered_jsonl_bytes)
                st.success(f"âœ… ì´ ë°ì´í„° ê°œìˆ˜: {dist['total_count']} / ì¤‘ë³µ ì—†ëŠ” ì›ë¬¸ ê°œìˆ˜: {dist['unique_content_count']}")

                pivot_data = []
                for post_type, emotion_counter in dist["type_emotion_counter"].items():
                    row = {"post_type": post_type}
                    for emotion in dist["emotion_order"]:
                        row[emotion] = emotion_counter.get(emotion, 0)
                    for emotion, count in emotion_counter.items():
                        if emotion not in dist["emotion_order"]:
                            row[emotion] = count
                    pivot_data.append(row)
                pivot_df = pd.DataFrame(pivot_data).set_index("post_type")
                st.dataframe(pivot_df, use_container_width=True)

                st.download_button(
                    label="ë‹¤ìš´ë¡œë“œ",
                    data=filtered_jsonl.encode("utf-8"),
                    file_name="filtered_all.jsonl",
                    mime="application/json"
                )
else:
    st.info("JSONL íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜, ìºì‹œì—ì„œ íŒŒì¼ì„ ì„ íƒí•˜ë©´ ëª¨ë¸ í‰ê°€ì™€ ë°ì´í„° ë¶„í¬ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")