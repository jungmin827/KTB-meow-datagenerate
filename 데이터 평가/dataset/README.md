
<<<<<<< HEAD
# 평가 모델 개발
## 데이터셋 
| 데이터셋 파일명                | 주요 특징 및 설명                                                                               |
|-------------------------------|--------------------------------------------------------------|
| test_made.jsonl                | 테스트용 Google AI Studio 합성 데이터.(100개)              |
| dataset_0515_made.jsonl        | 초기 유저 데이터.(342개)                                 |
| dataset_0527_made.jsonl        | 유저 게시글 데이터 기반 감정별/동물별 데이터 (818개)           |
| dataset_0530_made.jsonl        | 유저 게시글 데이터 기반 감정별/동물별 데이터 감정별 증폭(2,986개)   |
| dataset_0613_made.jsonl        | 유저 댓글 입력에 대한 규칙기반 변환(cat) 데이터(681개)         |
| dataset_0620_made.jsonl        | 유저 댓글 입력에 대한 규칙기반 변환(dog) 데이터(681개)          |
| dataset_0622_made.jsonl        | 합성 인풋에 대한 Gemini 말투 변환 최종본(17,596개).            |
| dataset_0629_made.jsonl        | 이전까지의 모든 데이터를 합친 통합 데이터.(21,104개)             |


# 파인튜닝 데이터셋 전처리 및 변환 도구 (`dataset/`)

이 디렉토리는 파인튜닝용 JSONL 데이터셋의 **정제, 필터링, 컬럼 변환, 후처리**를 위한 스크립트와 샘플 데이터를 포함합니다.

---

## 주요 파일 설명

- **preprocessing.py**  
  데이터셋의 품질을 높이기 위한 필터링, 텍스트 후처리, 중복제거, 통계 출력 등 전체 파이프라인 제공
- **comm_to_post.py**  
  컬럼명 일괄 변경, 컬럼 순서 지정, 라벨 추가 등 데이터 구조 변환 스크립트
- **_dataset/**  
  실제 데이터셋(jsonl) 파일 저장 폴더 (입력/출력/중간 결과 등)
- **data_maker.py**  
  (비어 있음, 추후 데이터 생성용 스크립트 작성 가능)

---

## 데이터 전처리/필터링 기준

### 1. **삭제(완전 제거) 조건**
- `content`, `transformed_content` 모두 없음
- 두 필드 모두 5자 미만이거나 의미 없는 텍스트(특수문자/숫자/공백만)
- 시스템/명령어/SQL/해킹 등 위험 키워드 포함(예: system, drop table, script, 해킹 등)

### 2. **수정(후처리) 조건**
- 해시태그, 이모지 과다/연속, 반복 단어, 비알파벳 시작, 변환 텍스트 과다 길이 등
- 후처리: 해시태그/특수공백/줄바꿈/특수문자/이모지/반복/불필요단어/공백 정리, 5자 미만 오류 메시지 대체, 200자 초과시 자르기 등

### 3. **중복 제거**
- 기본값: `content + emotion + post_type` 세 가지가 모두 같을 때만 중복으로 간주하여 1개만 남김
- 옵션으로 중복 제거를 끌 수도 있음

---

## 사용 방법

### 1. 데이터 전처리 및 필터링
```bash
python preprocessing.py -c [코드] [--skip N]
```
- `-c [코드]` : 데이터셋 파일명 코드 (예: 0615)
- `--skip N` : N번째 줄까지 데이터는 모두 건너뜀(선택)

### 2. 컬럼명/순서/라벨 변환
```bash
python comm_to_post.py
```
- 코드 내에서 입력/출력 파일명, 컬럼명 매핑, 라벨 지정 등 수정 가능

---

## 주요 함수 및 기능 요약

- **TextPostprocessor** : 텍스트 후처리(이모지, 해시태그, 반복, 특수공백, 불필요단어 등)
- **DataFilter** : 삭제/수정 조건 판별(위험키워드, 의미없음, 반복, 해시태그 등)
- **filter_and_postprocess** : 전체 파이프라인(중복제거, 삭제, 후처리, 컬럼정렬)
- **count_features** : post_type별 emotion 분포 통계 출력

---

## 예시

### 입력 데이터 예시
```json
{"content": "#내돈내산 오늘은 고기를 먹었다!", "transformed_content": "🐶🐶🐶🐶🐶 오늘은 정말 맛있는 고기를 먹었다!"}
{"content": "🐾🐾🐾 오늘은 고기를 먹었다!", "transformed_content": "오늘은 정말 맛있는 고기를 먹었다!"}
```

### 필터링 및 후처리 후 데이터 예시
```json
{"post_type": "cat", "emotion": "happy", "content": "오늘은 고기를 먹었다!", "transformed_content": "오늘은 정말 맛있는 고기를 먹었다!"}
```

---

## 참고

- 각 조건별 함수는 독립적으로 구현되어 있어, 필요에 따라 쉽게 수정/확장할 수 있습니다.
- 데이터셋 구조(필드)는 컬럼명 매핑/정렬로 유연하게 변경 가능합니다.
- 통계 출력으로 데이터 분포를 쉽게 확인할 수 있습니다.

---
